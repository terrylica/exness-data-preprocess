#!/usr/bin/env python3
"""
Phase 2: Mean Reversion Temporal Stability (16 Months)
======================================================
Correct methodology: Merge Standard (quotes) + Raw_Spread (execution)
Position ratio = (raw_mid - std_bid) / (std_ask - std_bid)

SLOs:
- Availability: ‚â•95% analysis success (max 1 failed month)
- Correctness: Exact match to Sep 2024 baseline formula
- Observability: Per-month metrics + statistical significance
"""

import logging
import warnings
import zipfile
from datetime import timedelta
from pathlib import Path

import numpy as np
import pandas as pd

warnings.filterwarnings("ignore")

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger(__name__)

DATA_DIR = Path("/tmp")
OUTPUT_FILE = DATA_DIR / "multiperiod_mean_reversion_results.csv"
REPORT_FILE = DATA_DIR / "multiperiod_mean_reversion_report.md"

# Sep 2024 baseline parameters
DEVIATION_THRESHOLD = 0.05
REVERSION_WINDOWS = [5, 10, 30, 60, 300, 600]
SAMPLE_SIZE = 5000


class AnalysisError(Exception):
    pass


def load_and_merge(month_str: str) -> pd.DataFrame:
    """Load Standard + Raw_Spread and merge (Sep 2024 methodology)"""
    year, month = month_str.split("-")

    # Load Standard (quotes: bid/ask spread)
    std_path = DATA_DIR / f"Exness_EURUSD_{year}_{month}.zip"
    if not std_path.exists():
        raise FileNotFoundError(f"Missing Standard: {std_path}")

    with zipfile.ZipFile(std_path) as zf:
        csv = [f for f in zf.namelist() if f.endswith(".csv")][0]
        with zf.open(csv) as f:
            std_df = pd.read_csv(f)

    std_df = std_df[["Timestamp", "Bid", "Ask"]].copy()
    std_df.columns = ["Timestamp", "std_bid", "std_ask"]
    std_df["Timestamp"] = pd.to_datetime(std_df["Timestamp"], utc=True)

    # Load Raw_Spread (execution prices)
    rs_path = DATA_DIR / f"Exness_EURUSD_Raw_Spread_{year}_{month}.zip"
    if not rs_path.exists():
        raise FileNotFoundError(f"Missing Raw_Spread: {rs_path}")

    with zipfile.ZipFile(rs_path) as zf:
        csv = [f for f in zf.namelist() if f.endswith(".csv")][0]
        with zf.open(csv) as f:
            rs_df = pd.read_csv(f)

    rs_df = rs_df[["Timestamp", "Bid", "Ask"]].copy()
    rs_df.columns = ["Timestamp", "raw_bid", "raw_ask"]
    rs_df["Timestamp"] = pd.to_datetime(rs_df["Timestamp"], utc=True)
    rs_df["raw_mid"] = (rs_df["raw_bid"] + rs_df["raw_ask"]) / 2
    rs_df["raw_spread"] = rs_df["raw_ask"] - rs_df["raw_bid"]

    # ASOF merge (Raw_Spread execution ‚Üí nearest Standard quote)
    # v1.0.5 FIX: Match baseline methodology exactly
    merged = pd.merge_asof(
        rs_df.sort_values("Timestamp"),
        std_df.sort_values("Timestamp"),
        on="Timestamp",
        direction="backward",  # FIX: was 'nearest' (lookahead bias)
        tolerance=pd.Timedelta(seconds=10),  # FIX: was 1 second (sample size mismatch)
    )

    merged = merged.dropna().reset_index(drop=True)

    # Compute position ratio (Sep 2024 formula)
    merged["position_ratio"] = (merged["raw_mid"] - merged["std_bid"]) / (
        merged["std_ask"] - merged["std_bid"]
    )

    # Filter to zero-spread events (threshold-based, not exact equality)
    # v1.0.5 FIX: Use threshold to handle floating-point precision
    zero_spread = merged[merged["raw_spread"] <= 0.00001].copy()  # FIX: was == 0

    logger.info(f"  {len(merged):,} total ticks, {len(zero_spread):,} zero-spread events")
    return zero_spread


def analyze_mean_reversion(df: pd.DataFrame, month_str: str) -> dict:
    """
    Analyze mean reversion for deviations
    Exact replication of Sep 2024 mean_reversion_analysis.py
    """
    if len(df) == 0:
        raise AnalysisError(f"No zero-spread events in {month_str}")

    # Identify deviations
    df["deviation"] = np.abs(df["position_ratio"] - 0.5)
    deviations = df[df["deviation"] > DEVIATION_THRESHOLD].copy()

    if len(deviations) == 0:
        raise AnalysisError(f"No deviations in {month_str}")

    # Sample for performance
    sample_size = min(SAMPLE_SIZE, len(deviations))
    deviations_sample = deviations.sample(n=sample_size, random_state=42).copy()

    logger.info(f"  Analyzing {sample_size:,} deviations (from {len(deviations):,} total)")

    results = {
        "month": month_str,
        "total_zero_spread": len(df),
        "deviation_count": len(deviations),
        "sample_size": sample_size,
        "mean_deviation": deviations["deviation"].mean(),
    }

    # Index for fast lookup
    df_indexed = df.set_index("Timestamp")

    for window_sec in REVERSION_WINDOWS:
        toward_mid = 0
        full_revert = 0
        measured = 0

        for idx, row in deviations_sample.iterrows():
            t0 = row["Timestamp"]
            t1 = t0 + timedelta(seconds=window_sec)

            # Future window
            future = df_indexed.loc[t0:t1]
            if len(future) < 2:
                continue

            measured += 1

            # Initial state
            initial_pos = row["position_ratio"]
            initial_dev = abs(initial_pos - 0.5)

            # Final state
            final_pos = future["position_ratio"].iloc[-1]
            final_dev = abs(final_pos - 0.5)

            # Reversion metrics
            if final_dev < initial_dev:
                toward_mid += 1

            if final_dev < DEVIATION_THRESHOLD:
                full_revert += 1

        # Store results
        if measured > 0:
            results[f"toward_{window_sec}s"] = toward_mid / measured
            results[f"full_{window_sec}s"] = full_revert / measured
            results[f"n_{window_sec}s"] = measured
        else:
            results[f"toward_{window_sec}s"] = np.nan
            results[f"full_{window_sec}s"] = np.nan
            results[f"n_{window_sec}s"] = 0

    return results


def main():
    logger.info("=" * 80)
    logger.info("PHASE 2: MEAN REVERSION TEMPORAL STABILITY (16 MONTHS)")
    logger.info("=" * 80)

    months = [
        "2024-01",
        "2024-02",
        "2024-03",
        "2024-04",
        "2024-05",
        "2024-06",
        "2024-07",
        "2024-08",
        "2025-01",
        "2025-02",
        "2025-03",
        "2025-04",
        "2025-05",
        "2025-06",
        "2025-07",
        "2025-08",
    ]

    all_results = []
    failed_months = []

    for month in months:
        logger.info(f"\nüìä Processing {month}...")
        try:
            df = load_and_merge(month)
            result = analyze_mean_reversion(df, month)
            all_results.append(result)
            logger.info(
                f"  ‚úÖ {result['toward_5s'] * 100:.1f}% toward @ 5s, "
                f"{result['full_5s'] * 100:.1f}% full @ 5s"
            )
        except Exception as e:
            logger.error(f"  ‚ùå FAILED: {e}")
            failed_months.append((month, str(e)))

    # Check SLO
    success_rate = len(all_results) / len(months)
    logger.info(f"\nüìä Success Rate: {success_rate * 100:.1f}% ({len(all_results)}/{len(months)})")

    if success_rate < 0.95:
        raise AnalysisError(f"SLO violation: {success_rate * 100:.1f}% < 95%")

    # Save results
    results_df = pd.DataFrame(all_results)
    results_df.to_csv(OUTPUT_FILE, index=False)
    logger.info(f"\n‚úÖ Results saved: {OUTPUT_FILE}")

    # Statistical summary
    logger.info("\n" + "=" * 80)
    logger.info("STATISTICAL SUMMARY")
    logger.info("=" * 80)

    for window in [5, 60, 300]:
        col = f"toward_{window}s"
        if col in results_df.columns:
            mean = results_df[col].mean()
            std = results_df[col].std()
            logger.info(f"\n{window}s Window: {mean * 100:.1f}% ¬± {std * 100:.1f}%")

    # Year-over-year
    results_df["year"] = results_df["month"].str[:4]
    logger.info("\n" + "=" * 80)
    logger.info("YEAR-OVER-YEAR COMPARISON")
    logger.info("=" * 80)

    for year in ["2024", "2025"]:
        year_data = results_df[results_df["year"] == year]
        if len(year_data) > 0:
            logger.info(f"\n{year} ({len(year_data)} months):")
            logger.info(
                f"  Toward @ 5s: {year_data['toward_5s'].mean() * 100:.1f}% ¬± "
                f"{year_data['toward_5s'].std() * 100:.1f}%"
            )
            logger.info(
                f"  Full @ 5s: {year_data['full_5s'].mean() * 100:.1f}% ¬± "
                f"{year_data['full_5s'].std() * 100:.1f}%"
            )

    # Verdict
    logger.info("\n" + "=" * 80)
    logger.info("PHASE 2 COMPLETE")
    logger.info("=" * 80)

    stability = "STABLE" if results_df["toward_5s"].std() < 0.05 else "VARIABLE"
    logger.info(f"Temporal Stability: {stability} (œÉ={results_df['toward_5s'].std() * 100:.1f}%)")

    # Generate report
    report_lines = [
        "# Phase 2: Mean Reversion Temporal Stability",
        f"**Analysis Date:** {pd.Timestamp.now().strftime('%Y-%m-%d')}",
        f"**Months Analyzed:** {len(all_results)}/16",
        f"**Success Rate:** {success_rate * 100:.1f}%",
        "",
        "## Results Summary",
        "",
        "| Window | Mean | Std | Min | Max |",
        "|--------|------|-----|-----|-----|",
    ]

    for window in [5, 10, 60, 300]:
        col = f"toward_{window}s"
        if col in results_df.columns:
            report_lines.append(
                f"| {window}s | {results_df[col].mean() * 100:.1f}% | "
                f"{results_df[col].std() * 100:.1f}% | "
                f"{results_df[col].min() * 100:.1f}% | "
                f"{results_df[col].max() * 100:.1f}% |"
            )

    report_lines.extend(
        [
            "",
            "## Year-over-Year",
            "",
        ]
    )

    for year in ["2024", "2025"]:
        year_data = results_df[results_df["year"] == year]
        if len(year_data) > 0:
            report_lines.extend(
                [
                    f"### {year}",
                    f"- Toward @ 5s: {year_data['toward_5s'].mean() * 100:.1f}% ¬± {year_data['toward_5s'].std() * 100:.1f}%",
                    f"- Full @ 5s: {year_data['full_5s'].mean() * 100:.1f}% ¬± {year_data['full_5s'].std() * 100:.1f}%",
                    "",
                ]
            )

    report_lines.extend(
        [
            "## Conclusion",
            "",
            f"Pattern is **{stability}** across 16 months (œÉ={results_df['toward_5s'].std() * 100:.1f}%).",
            "",
            "**SLO Status:** ‚úÖ PASS",
        ]
    )

    with open(REPORT_FILE, "w") as f:
        f.write("\n".join(report_lines))

    logger.info(f"‚úÖ Report saved: {REPORT_FILE}")


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        logger.error(f"FATAL: {e}")
        raise
