#!/usr/bin/env python3
"""
Phase 2: Mean Reversion Temporal Stability (16 Months)
======================================================
Correct methodology: Merge Standard (quotes) + Raw_Spread (execution)
Position ratio = (raw_mid - std_bid) / (std_ask - std_bid)

SLOs:
- Availability: ‚â•95% analysis success (max 1 failed month)
- Correctness: Exact match to Sep 2024 baseline formula
- Observability: Per-month metrics + statistical significance
"""
import pandas as pd
import numpy as np
import logging
import zipfile
from pathlib import Path
from datetime import timedelta
import warnings
warnings.filterwarnings('ignore')

logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
logger = logging.getLogger(__name__)

DATA_DIR = Path("/tmp")
OUTPUT_FILE = DATA_DIR / "multiperiod_mean_reversion_results.csv"
REPORT_FILE = DATA_DIR / "multiperiod_mean_reversion_report.md"

# Sep 2024 baseline parameters
DEVIATION_THRESHOLD = 0.05
REVERSION_WINDOWS = [5, 10, 30, 60, 300, 600]
SAMPLE_SIZE = 5000

class AnalysisError(Exception):
    pass

def load_and_merge(month_str: str) -> pd.DataFrame:
    """Load Standard + Raw_Spread and merge (Sep 2024 methodology)"""
    year, month = month_str.split('-')

    # Load Standard (quotes: bid/ask spread)
    std_path = DATA_DIR / f"Exness_EURUSD_{year}_{month}.zip"
    if not std_path.exists():
        raise FileNotFoundError(f"Missing Standard: {std_path}")

    with zipfile.ZipFile(std_path) as zf:
        csv = [f for f in zf.namelist() if f.endswith('.csv')][0]
        with zf.open(csv) as f:
            std_df = pd.read_csv(f)

    std_df = std_df[['Timestamp', 'Bid', 'Ask']].copy()
    std_df.columns = ['Timestamp', 'std_bid', 'std_ask']
    std_df['Timestamp'] = pd.to_datetime(std_df['Timestamp'], utc=True)

    # Load Raw_Spread (execution prices)
    rs_path = DATA_DIR / f"Exness_EURUSD_Raw_Spread_{year}_{month}.zip"
    if not rs_path.exists():
        raise FileNotFoundError(f"Missing Raw_Spread: {rs_path}")

    with zipfile.ZipFile(rs_path) as zf:
        csv = [f for f in zf.namelist() if f.endswith('.csv')][0]
        with zf.open(csv) as f:
            rs_df = pd.read_csv(f)

    rs_df = rs_df[['Timestamp', 'Bid', 'Ask']].copy()
    rs_df.columns = ['Timestamp', 'raw_bid', 'raw_ask']
    rs_df['Timestamp'] = pd.to_datetime(rs_df['Timestamp'], utc=True)
    rs_df['raw_mid'] = (rs_df['raw_bid'] + rs_df['raw_ask']) / 2
    rs_df['raw_spread'] = rs_df['raw_ask'] - rs_df['raw_bid']

    # ASOF merge (Raw_Spread execution ‚Üí nearest Standard quote)
    # v1.0.5 FIX: Match baseline methodology exactly
    merged = pd.merge_asof(
        rs_df.sort_values('Timestamp'),
        std_df.sort_values('Timestamp'),
        on='Timestamp',
        direction='backward',  # FIX: was 'nearest' (lookahead bias)
        tolerance=pd.Timedelta(seconds=10)  # FIX: was 1 second (sample size mismatch)
    )

    merged = merged.dropna().reset_index(drop=True)

    # Compute position ratio (Sep 2024 formula)
    merged['position_ratio'] = (
        (merged['raw_mid'] - merged['std_bid']) /
        (merged['std_ask'] - merged['std_bid'])
    )

    # Filter to zero-spread events (threshold-based, not exact equality)
    # v1.0.5 FIX: Use threshold to handle floating-point precision
    zero_spread = merged[merged['raw_spread'] <= 0.00001].copy()  # FIX: was == 0

    logger.info(f"  {len(merged):,} total ticks, {len(zero_spread):,} zero-spread events")
    return zero_spread

def analyze_mean_reversion(df: pd.DataFrame, month_str: str) -> dict:
    """
    Analyze mean reversion for deviations
    Exact replication of Sep 2024 mean_reversion_analysis.py
    """
    if len(df) == 0:
        raise AnalysisError(f"No zero-spread events in {month_str}")

    # Identify deviations
    df['deviation'] = np.abs(df['position_ratio'] - 0.5)
    deviations = df[df['deviation'] > DEVIATION_THRESHOLD].copy()

    if len(deviations) == 0:
        raise AnalysisError(f"No deviations in {month_str}")

    # Sample for performance
    sample_size = min(SAMPLE_SIZE, len(deviations))
    deviations_sample = deviations.sample(n=sample_size, random_state=42).copy()

    logger.info(f"  Analyzing {sample_size:,} deviations (from {len(deviations):,} total)")

    results = {
        'month': month_str,
        'total_zero_spread': len(df),
        'deviation_count': len(deviations),
        'sample_size': sample_size,
        'mean_deviation': deviations['deviation'].mean(),
    }

    # Index for fast lookup
    df_indexed = df.set_index('Timestamp')

    for window_sec in REVERSION_WINDOWS:
        toward_mid = 0
        full_revert = 0
        measured = 0

        for idx, row in deviations_sample.iterrows():
            t0 = row['Timestamp']
            t1 = t0 + timedelta(seconds=window_sec)

            # Future window
            future = df_indexed.loc[t0:t1]
            if len(future) < 2:
                continue

            measured += 1

            # Initial state
            initial_pos = row['position_ratio']
            initial_dev = abs(initial_pos - 0.5)

            # Final state
            final_pos = future['position_ratio'].iloc[-1]
            final_dev = abs(final_pos - 0.5)

            # Reversion metrics
            if final_dev < initial_dev:
                toward_mid += 1

            if final_dev < DEVIATION_THRESHOLD:
                full_revert += 1

        # Store results
        if measured > 0:
            results[f'toward_{window_sec}s'] = toward_mid / measured
            results[f'full_{window_sec}s'] = full_revert / measured
            results[f'n_{window_sec}s'] = measured
        else:
            results[f'toward_{window_sec}s'] = np.nan
            results[f'full_{window_sec}s'] = np.nan
            results[f'n_{window_sec}s'] = 0

    return results

def main():
    logger.info("=" * 80)
    logger.info("PHASE 2: MEAN REVERSION TEMPORAL STABILITY (16 MONTHS)")
    logger.info("=" * 80)

    months = [
        '2024-01', '2024-02', '2024-03', '2024-04',
        '2024-05', '2024-06', '2024-07', '2024-08',
        '2025-01', '2025-02', '2025-03', '2025-04',
        '2025-05', '2025-06', '2025-07', '2025-08'
    ]

    all_results = []
    failed_months = []

    for month in months:
        logger.info(f"\nüìä Processing {month}...")
        try:
            df = load_and_merge(month)
            result = analyze_mean_reversion(df, month)
            all_results.append(result)
            logger.info(f"  ‚úÖ {result['toward_5s']*100:.1f}% toward @ 5s, "
                       f"{result['full_5s']*100:.1f}% full @ 5s")
        except Exception as e:
            logger.error(f"  ‚ùå FAILED: {e}")
            failed_months.append((month, str(e)))

    # Check SLO
    success_rate = len(all_results) / len(months)
    logger.info(f"\nüìä Success Rate: {success_rate*100:.1f}% ({len(all_results)}/{len(months)})")

    if success_rate < 0.95:
        raise AnalysisError(f"SLO violation: {success_rate*100:.1f}% < 95%")

    # Save results
    results_df = pd.DataFrame(all_results)
    results_df.to_csv(OUTPUT_FILE, index=False)
    logger.info(f"\n‚úÖ Results saved: {OUTPUT_FILE}")

    # Statistical summary
    logger.info("\n" + "=" * 80)
    logger.info("STATISTICAL SUMMARY")
    logger.info("=" * 80)

    for window in [5, 60, 300]:
        col = f'toward_{window}s'
        if col in results_df.columns:
            mean = results_df[col].mean()
            std = results_df[col].std()
            logger.info(f"\n{window}s Window: {mean*100:.1f}% ¬± {std*100:.1f}%")

    # Year-over-year
    results_df['year'] = results_df['month'].str[:4]
    logger.info("\n" + "=" * 80)
    logger.info("YEAR-OVER-YEAR COMPARISON")
    logger.info("=" * 80)

    for year in ['2024', '2025']:
        year_data = results_df[results_df['year'] == year]
        if len(year_data) > 0:
            logger.info(f"\n{year} ({len(year_data)} months):")
            logger.info(f"  Toward @ 5s: {year_data['toward_5s'].mean()*100:.1f}% ¬± "
                       f"{year_data['toward_5s'].std()*100:.1f}%")
            logger.info(f"  Full @ 5s: {year_data['full_5s'].mean()*100:.1f}% ¬± "
                       f"{year_data['full_5s'].std()*100:.1f}%")

    # Verdict
    logger.info("\n" + "=" * 80)
    logger.info("PHASE 2 COMPLETE")
    logger.info("=" * 80)

    stability = "STABLE" if results_df['toward_5s'].std() < 0.05 else "VARIABLE"
    logger.info(f"Temporal Stability: {stability} (œÉ={results_df['toward_5s'].std()*100:.1f}%)")

    # Generate report
    report_lines = [
        "# Phase 2: Mean Reversion Temporal Stability",
        f"**Analysis Date:** {pd.Timestamp.now().strftime('%Y-%m-%d')}",
        f"**Months Analyzed:** {len(all_results)}/16",
        f"**Success Rate:** {success_rate*100:.1f}%",
        "",
        "## Results Summary",
        "",
        f"| Window | Mean | Std | Min | Max |",
        f"|--------|------|-----|-----|-----|",
    ]

    for window in [5, 10, 60, 300]:
        col = f'toward_{window}s'
        if col in results_df.columns:
            report_lines.append(
                f"| {window}s | {results_df[col].mean()*100:.1f}% | "
                f"{results_df[col].std()*100:.1f}% | "
                f"{results_df[col].min()*100:.1f}% | "
                f"{results_df[col].max()*100:.1f}% |"
            )

    report_lines.extend([
        "",
        "## Year-over-Year",
        "",
    ])

    for year in ['2024', '2025']:
        year_data = results_df[results_df['year'] == year]
        if len(year_data) > 0:
            report_lines.extend([
                f"### {year}",
                f"- Toward @ 5s: {year_data['toward_5s'].mean()*100:.1f}% ¬± {year_data['toward_5s'].std()*100:.1f}%",
                f"- Full @ 5s: {year_data['full_5s'].mean()*100:.1f}% ¬± {year_data['full_5s'].std()*100:.1f}%",
                "",
            ])

    report_lines.extend([
        f"## Conclusion",
        f"",
        f"Pattern is **{stability}** across 16 months (œÉ={results_df['toward_5s'].std()*100:.1f}%).",
        f"",
        f"**SLO Status:** ‚úÖ PASS",
    ])

    with open(REPORT_FILE, 'w') as f:
        f.write('\n'.join(report_lines))

    logger.info(f"‚úÖ Report saved: {REPORT_FILE}")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        logger.error(f"FATAL: {e}")
        raise
