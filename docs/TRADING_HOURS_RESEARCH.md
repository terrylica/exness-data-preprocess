# Trading Hours Detection in Financial Data Systems: Research & Best Practices

**Date**: 2025-10-17
**Context**: Forex tick data preprocessing system requiring trading hour flagging for exchange sessions
**Scope**: Industry standards, architectural patterns, scalability, edge cases, and proven implementations

---

## Executive Summary

This research examined best practices for implementing trading hours detection across:
- **5 major quantitative finance libraries** (exchange_calendars, pandas_market_calendars, zipline, backtrader, QuantConnect)
- **3 professional data platforms** (TradingHours.com, Bloomberg, QuantConnect)
- **4 time-series database systems** (DuckDB, ClickHouse, Arctic, InfluxDB)
- **Industry edge cases** (DST transitions, timezone handling, historical hour changes)

**Key Finding**: The industry overwhelmingly favors **separation of concerns** - dedicated calendar/session libraries combined with query-time filtering rather than storage-time flag computation.

---

## 1. Industry Standard Libraries

### 1.1 exchange_calendars (Quantopian → Community Maintained)

**Repository**: https://github.com/gerrymanoim/exchange_calendars
**PyPI**: exchange_calendars
**Exchanges**: 50+ global exchanges (NYSE, LSE, XTKS, etc.)

#### Architecture Pattern: Calendar Abstraction

```python
# Core design: Separation between calendar definition and data
import exchange_calendars as xcals

xnys = xcals.get_calendar("XNYS")  # New York Stock Exchange

# Session-level queries (daily granularity)
xnys.is_session("2022-01-01")  # False (holiday)
sessions = xnys.sessions_in_range("2022-01-01", "2022-01-11")

# Minute-level queries (intraday granularity)
minutes = xnys.session_minutes("2022-01-10")
is_trading = xnys.is_trading_minute("2022-01-10 14:30")
```

#### Key Architectural Decisions

1. **Sessions vs Minutes Distinction**
   - **Sessions**: Trading days with open/close times, breaks, holidays
   - **Minutes**: Individual trading minutes within sessions
   - Enables both coarse-grained and fine-grained queries without conflation

2. **Break Handling**
   - Explicit schedule columns: `break_start`, `break_end`
   - Methods like `is_break_minute()` query directly
   - Asian markets (lunch breaks) and futures (processing breaks) supported uniformly

3. **Registration System**
   - `register_calendar()` and `register_calendar_type()` for runtime discovery
   - Decouples calendar definitions from discovery mechanisms
   - Subclass pattern: `ExchangeCalendar` base class with 50+ implementations

4. **Timezone Handling**
   - All timestamps include UTC timezone information
   - Each calendar has `.tz` property returning ZoneInfo object
   - Internal UTC representation prevents DST ambiguity

5. **Edge Cases**
   - Pre/post-trading and auction periods: Treated as **closed** (not special session types)
   - Holidays: Missing rows in schedule DataFrame
   - Minute semantics: "side" parameter (left/right closure) handles different interpretations

#### API Design Lessons

- **Pandas Integration**: Leverages DataFrames for schedules
  ```python
  schedule.loc["2021-12-29":"2022-01-04"]  # Familiar slicing
  ```
- **Boolean + Navigation Methods**: Both checking and traversal
  ```python
  is_session()  # Boolean check
  previous_session()  # Navigation
  next_market_open()  # Navigation
  ```
- **Batch Operations**: Avoids N+1 query patterns
  ```python
  sessions_in_range()  # Not: [is_session(d) for d in dates]
  session_minutes()    # Not: [is_trading_minute(m) for m in minutes]
  ```

---

### 1.2 pandas_market_calendars

**Repository**: https://github.com/rsheftel/pandas_market_calendars
**PyPI**: pandas_market_calendars
**Notable**: Mirrors exchange_calendars calendars + adds customization

#### Key Features for Trading Hours

1. **Intraday Breaks** (v1.4+)
   - Accommodates Asian markets (lunch breaks)
   - Futures markets (24-hour with processing breaks)

2. **Historical Hour Changes**
   - `regular_market_times` property shows historical changes
   - Example: NYSE open/close times changed over decades

3. **Customization API**
   ```python
   import datetime
   from pandas_market_calendars import get_calendar

   # Override market times
   custom = get_calendar("NYSE",
                         open_time=datetime.time(9, 0),
                         close_time=datetime.time(16, 30))
   ```

4. **Date Range with Market Hours**
   ```python
   # Only datetimes when markets are open
   cal.date_range(start="2022-01-01", end="2022-01-31", frequency="1H")
   ```

5. **Timezone Migration** (v5.0+)
   - Deprecated `pytz` in favor of Python 3.9+ `zoneinfo` standard
   - Requires Python 3.9 minimum

#### Product-Specific Calendars

- Futures exchanges: Different calendars per product type
- Example: CME has different hours for equity futures vs energy futures

---

### 1.3 zipline (Quantopian Backtesting Engine)

**Repository**: https://github.com/quantopian/zipline
**Docs**: https://zipline-trader.readthedocs.io/en/latest/trading-calendars.html

#### Session Model

- **Session**: Contiguous set of minutes with midnight UTC label
- **Default**: NYSE hours (9:30 AM - 4:00 PM EST, Mon-Fri, excluding holidays)

#### Minute Bar Labeling Convention

**Critical Design Choice**: "9:31:00 is the first time treated as open" (not 9:30:00)

**Rationale**: Minute bars labeled by **completion time** not start time
- 9:30 AM bar spans 9:30:00-9:30:59, labeled as 9:31
- Aligns with backtesting system where bar data available *after* period ends

#### Custom Calendar Implementation

```python
from trading_calendars import TradingCalendar
from datetime import time
import pandas as pd
from pytz import timezone

class CustomCalendar(TradingCalendar):
    name = "CUSTOM"
    tz = timezone("US/Eastern")
    open_time = time(9, 30)
    close_time = time(16, 0)

    @property
    def adhoc_holidays(self):
        return pd.DatetimeIndex([...])
```

---

### 1.4 backtrader

**Docs**: https://www.backtrader.com/docu/tradingcalendar/tradingcalendar/

#### Timezone Architecture

1. **Internal UTC Standard**
   - All data feed times converted to UTC internally
   - "UTC-like format" for internal time representation

2. **Data Feed Configuration**
   - `tzinput`: Input timezone (datetime.tzinfo compatible)
   - `tz`: Output timezone for strategy display
   - Example: `tzinput='CET'` and `tz='US/Eastern'` for input/output transformation

3. **Strategy Timezone Display**
   - Cerebro's `tz` parameter: Global timezone for strategies
   - `tz=None`: Display in UTC
   - `tz=pytz.timezone('US/Eastern')`: Display in Eastern

4. **Session Time Detection with Timers**
   - `SESSION_START` / `SESSION_END` events
   - `tzdata` parameter:
     - `None`: Interpreted as UTC
     - `pytz instance`: Interpreted in local timezone
   - If `tzdata=None`, uses first data feed (`self.data0`) for session reference

---

### 1.5 QuantConnect

**Docs**: https://www.quantconnect.com/docs/v2/writing-algorithms/securities/market-hours

#### SecurityExchangeHours Architecture

```python
# Access exchange hours
security = self.AddEquity("SPY")
hours = security.Exchange.Hours

# Time-based queries
is_open = hours.is_open(datetime, extended_hours=False)
is_date_open = hours.is_date_open(date)

# Navigation
next_open = hours.get_next_market_open(current_time)
next_close = hours.get_next_market_close(current_time)
prev_day = hours.get_previous_trading_day(current_time)
```

#### Data Resolution and Extended Hours

- **Daily/Hourly Resolution**: Only regular trading hours
- **Minute/Second/Tick Resolution**: Can include extended hours
- **Crypto**: 24/7 trading, no extended hours concept
- **Traditional Assets**: Official schedules affected by DST, holidays, trading halts

#### Real-World Impact

QuantConnect's design reflects **professional system requirements**:
- Explicit extended hours handling (pre-market, post-market)
- DST-aware scheduling
- Trading halt detection
- Multiple asset class support (equity, futures, crypto, forex)

---

## 2. Professional Data Providers

### 2.1 TradingHours.com

**Service**: https://www.tradinghours.com
**API**: https://github.com/tradinghours/tradinghours-python

#### Coverage
- **1,000+ exchanges and trading venues** worldwide
- Daily data updates
- Comprehensive market holidays and trading hours

#### Use Case
- Relied upon by thousands of financial professionals
- Prevents online-offline skew in production systems
- Single source of truth for session data

**Key Insight**: Professional systems outsource calendar management rather than maintaining in-house implementations

---

### 2.2 Bloomberg

**Products**: B-PIPE (real-time), Data License (historical)

#### Findings (Limited Public Documentation)
- Intraday bar data filterable by session type (regular vs extended)
- Tick data includes timezone offset metadata
- Pre-market and post-market session flags in analytics products
- Proprietary session detection (not publicly documented)

**Search Note**: Bloomberg's specific session flag implementation is proprietary. Public documentation focuses on data delivery rather than internal data models.

---

### 2.3 Reuters Datascope Select

**Product**: LSEG DataScope Select Data Delivery

#### Coverage
- 80 million+ exchange-traded and OTC securities
- Equities, futures, options, FX, rates, credit, commodities
- Reference data updates every 15 minutes (DataScope Plus)

#### Architecture Pattern
- Departure from vertical packages → unified cross-asset platform
- Single connection for multiple market segments
- **Observation**: Session methodology not publicly documented (proprietary)

---

## 3. Scalability Patterns for Billion-Row Datasets

### 3.1 DuckDB Performance Profile

**Sources**:
- https://towardsdatascience.com/my-first-billion-of-rows-in-duckdb-11873e5edbb5
- https://www.vantage.sh/blog/querying-aws-cost-data-duckdb
- https://github.com/terrylica/exness-data-preprocess (this project)

#### Performance Metrics

| Operation | DuckDB | PostgreSQL | Speedup |
|-----------|--------|------------|---------|
| COUNT(1B rows) | <2s | 400s | 200x |
| GROUP BY (200M rows) | 4s | 420s+ | 100x+ |
| Complex subqueries | 4s | 7min+ | 100x+ |

#### Architectural Advantages for Trading Hours Flags

1. **Columnar Storage**
   - Read only columns needed (e.g., timestamp, session_flag)
   - Skips irrelevant data (bid, ask, volume)

2. **Vectorized Execution**
   - Processes 1000+ rows per chunk using SIMD instructions
   - Optimized for CPU cache efficiency

3. **Automatic Parallelization**
   - Uses all available cores without configuration
   - Ideal for batch flag computation

4. **Zone Maps**
   - Selective scanning with min/max metadata
   - Skip entire chunks if timestamp outside session hours

5. **Compression**
   - CSV 21GB → DuckDB 1.7GB
   - Run-Length Encoding (RLE) ideal for repeated flags (0/1 values)

#### Real-World Example: Forex Tick Data

**Project**: exness-data-preprocess (this research context)
- **Performance**: Sub-15ms query performance
- **Storage**: Unified single-file DuckDB per instrument
- **Scale**: Millions of tick records per instrument
- **Pattern**: Query-time session detection with `exchange_calendars`

**Recommendation**: DuckDB excels at query-time flag computation vs storage-time pre-computation

---

### 3.2 ClickHouse Materialized Views

**Source**: https://clickhouse.com/blog/using-materialized-views-in-clickhouse

#### Two Types

1. **Incremental Materialized Views**
   - Update automatically in real-time on insert
   - Use case: Pre-compute session flags during data ingestion

2. **Refreshable Materialized Views**
   - Execute periodically (not incrementally)
   - Use case: Hourly/daily re-computation of session flags

#### Performance Considerations

**Trade-offs**:
- **Benefit**: Faster query time (pre-computed results)
- **Cost**: Insert performance degradation
  - Each materialized view ≥ doubles write data
  - 50+ views → 50x reduction in insert QPS

**Recommendation for Trading Hours**:
- Avoid materialized views for session flags
- Use columnar indexing + query-time computation instead
- Exception: If <10 flag types and write load tolerates 2x overhead

---

### 3.3 Arctic TimeSeries Database

**Repository**: https://github.com/man-group/arctic
**Maintainer**: Man AHL (quantitative hedge fund)

#### TickStore Design

- **Storage**: Column-oriented tick database, chunks stored in MongoDB
- **Performance**: Millions of rows/second, 800M messages/day ingestion
- **Compression**: 60% reduction vs previous solutions
- **Speed**: 25x faster model fitting for quants

#### Session Filtering Pattern

```python
from arctic import Arctic
store = Arctic('localhost')
library = store['tick_data']

# Query with date_range filter
ticks = library.read('EURUSD', date_range=DateRange(start, end))
```

**Architecture Insight**:
- No built-in session flag storage
- Date range filtering only
- **Application-layer session detection** expected

**Key Takeaway**: Even high-frequency trading systems (Man AHL) don't pre-compute session flags in storage layer

---

### 3.4 InfluxDB Time-Series Database

**Docs**: https://docs.influxdata.com/influxdb/

#### Schema Best Practices for Financial Data

**Tags** (indexed):
- `symbol`, `exchange`, `session_type` (metadata for filtering)

**Fields** (not indexed):
- `price`, `volume`, `bid`, `ask` (numeric values)

**Design Decision**: Session type as **tag** not field
- **Rationale**: Tags indexed → fast filtering
- **Query**: `SELECT * FROM ticks WHERE session_type='regular_hours'`

#### Continuous Queries for Aggregation

```sql
-- Automatic OHLCV generation from ticks
CREATE CONTINUOUS QUERY "cq_1min_bars" ON "market_data"
BEGIN
  SELECT first(price) AS open, max(price) AS high,
         min(price) AS low, last(price) AS close,
         sum(volume) AS volume
  INTO "bars_1min"
  FROM "ticks"
  GROUP BY time(1m), symbol, session_type
END
```

**Session Handling**: `session_type` tag enables session-aware aggregations

#### Retention Policies

- **High-resolution ticks**: 7 days (raw with session flags)
- **1-minute bars**: 90 days (aggregated with session flags)
- **Daily bars**: Indefinite (downsampled, session summary)

**Scalability Pattern**: Progressive aggregation with session metadata propagation

---

### 3.5 QuestDB (Specialized for Financial Tick Data)

**Website**: https://questdb.com

#### Features for Trading Applications

- **Time-series optimization**: Built for tick data, trades, order books, OHLC
- **Precision**: Nanosecond timestamps
- **Joins**: ASOF joins (critical for tick-level session alignment)
- **Materialized views**: Session-aware aggregations

#### Target Market
- Trading floors
- Mission control systems
- Real-time trading operations

**Observation**: Specialized databases for financial data exist but still require application-layer session logic

---

## 4. Edge Cases and Error Handling

### 4.1 Daylight Saving Time (DST) Transitions

**Sources**:
- https://fxglobe.com/daylight-saving-times-dts-2024-changes-to-trading-hours/
- https://medium.com/@OFPFunding/how-does-daylight-saving-time-impact-forex-trading-a00864eb02fa

#### Critical Edge Cases

1. **Regional Misalignment**
   - US DST: Second Sunday in March / First Sunday in November
   - EU DST: Last Sunday in March / Last Sunday in October
   - **Impact**: 2-3 weeks per year with misaligned session overlaps

2. **Algorithmic Trading System Failures**
   - Algorithms not configured for DST → trades execute 1 hour off schedule
   - Missing optimal entry points or trading during illiquid periods
   - **Best Practice**: Use UTC internally, convert to local time only for display

3. **Options Expiration Timing**
   - US options expire at 4:00 PM ET (whether EST or EDT)
   - International traders see expiration "shift" during DST mismatches
   - **Solution**: Store expiration in exchange local time + UTC offset

4. **Settlement Coordination**
   - T+1 settlement calculations need business days in both jurisdictions
   - Currency settlement cutoffs shift relative to equity market closes
   - **Pattern**: Explicit timezone handling in settlement logic

5. **Market Volatility Spike**
   - Research shows increased volatility in days following DST changes
   - Stocks tend to fall, uncertainty introduced
   - **System Impact**: Risk management systems must account for DST periods

#### Best Practices

```python
# DON'T: Store local time without timezone
timestamp = "2024-03-10 09:30:00"  # Ambiguous during DST

# DO: Store UTC with explicit timezone conversion
from zoneinfo import ZoneInfo
utc_time = datetime(2024, 3, 10, 14, 30, tzinfo=ZoneInfo("UTC"))
local_time = utc_time.astimezone(ZoneInfo("America/New_York"))
```

**Library Support**:
- `exchange_calendars`: UTC internal + zoneinfo conversion
- `pandas_market_calendars`: Migrated from pytz to zoneinfo (v5.0)
- `backtrader`: UTC internal, tzdata parameter for display

---

### 4.2 Historical Hour Changes

**Example**: Tokyo Stock Exchange (Nov 5, 2024)

**Source**: https://asia.nikkei.com/business/markets/tokyo-stock-exchange-moves-to-extend-trading-by-half-hour-in-2024

#### Change Details
- **Previous**: 9:00 AM - 3:00 PM (with lunch break)
- **New**: 9:00 AM - 3:30 PM (first change in 70 years)
- **Effective**: November 5, 2024

#### Implementation Pattern

**exchange_calendars approach**:
```python
class XTKS(ExchangeCalendar):
    def __init__(self):
        # Historical close times
        self.close_times = [
            (None, time(15, 0)),           # Before Nov 5, 2024
            (pd.Timestamp("2024-11-05"), time(15, 30))  # After
        ]
```

#### Cboe Japan Simultaneously Changed
- Same date: November 5, 2024
- Coordination required for multi-exchange systems

**Lesson**: Calendar libraries must support **temporal versioning** of hours

---

### 4.3 Forex Trading Hours Edge Cases

**Source**: https://www.earnforex.com/guides/making-sense-of-forex-trading-sessions-and-time-zones/

#### Forex-Specific Challenges

1. **24-Hour Market with Gaps**
   - Opens: 10 PM UTC Sunday (Sydney)
   - Closes: 10 PM UTC Friday (New York)
   - **Gap**: Friday 10 PM - Sunday 10 PM (weekend)

2. **Session Overlaps**
   - London + New York: 1:00 PM - 4:00 PM UTC (highest liquidity)
   - Tokyo + London: 8:00 AM - 9:00 AM UTC
   - Sydney + Tokyo: 12:00 AM - 6:00 AM UTC
   - **Pattern**: Track multiple concurrent sessions, not single session flag

3. **DST Coordination**
   - Not all countries observe DST
   - Sessions affected differently
   - **Example**:
     - US DST (March): New York session shifts 1 hour relative to London
     - UK DST (March): London session shifts
     - **Result**: 2-3 week misalignment

4. **Best Practice from Professional Traders**
   > "List your pairs, the two best windows for each (in UTC and your local time), and the top three data releases you trade. Update twice a year for DST and forget the rest."

**Recommendation**:
- Store session times in **UTC**
- Provide session overlap detection
- Warn when DST transitions occur

---

### 4.4 Timezone Implementation Patterns

#### Python's zoneinfo (Python 3.9+)

**Standard Library Approach** (Recommended):
```python
from zoneinfo import ZoneInfo
from datetime import datetime

# Exchange local time → UTC
nyse_open = datetime(2024, 10, 17, 9, 30, tzinfo=ZoneInfo("America/New_York"))
utc_open = nyse_open.astimezone(ZoneInfo("UTC"))

# DST handled automatically by IANA database
```

**Why zoneinfo over pytz**:
- Python 3.9+ standard library (no dependency)
- IANA Time Zone Database maintained by Python core
- Handles historical DST rule changes
- Used by pandas_market_calendars v5.0+

#### Handling DST Ambiguity

**Ambiguous Times** (DST "fall back" creates duplicate hour):
```python
# 1:30 AM on Nov 3, 2024 occurs twice (EDT → EST transition)
ambiguous = datetime(2024, 11, 3, 1, 30)

# Disambiguate with fold parameter
before_transition = ambiguous.replace(fold=0)  # First occurrence (EDT)
after_transition = ambiguous.replace(fold=1)   # Second occurrence (EST)
```

**Non-existent Times** (DST "spring forward" skips hour):
```python
# 2:30 AM on Mar 10, 2024 doesn't exist (EST → EDT transition)
# ZoneInfo raises exception if used carelessly

# Solution: Store UTC, convert to local for display only
```

---

## 5. Architectural Patterns

### 5.1 Separation of Concerns

**Pattern**: Dedicated calendar library + data storage + query-time filtering

#### Why This Pattern Dominates

**Evidence**:
- **exchange_calendars**: 50+ exchange calendars, no storage layer
- **pandas_market_calendars**: Calendar definitions, delegates storage to pandas
- **Arctic TickStore**: High-performance tick storage, no session flags
- **QuantConnect**: `SecurityExchangeHours` abstraction, separate from data

#### Implementation Architecture

```
┌─────────────────────┐
│  Calendar Library   │  ← exchange_calendars, pandas_market_calendars
│  (Session Rules)    │
└──────────┬──────────┘
           │
           │ Query at Runtime
           │
┌──────────▼──────────┐
│   Data Storage      │  ← DuckDB, Parquet, Arctic, InfluxDB
│   (Tick/OHLC Data)  │     (No session flags stored)
└─────────────────────┘
```

#### Benefits

1. **Single Source of Truth**
   - Calendar updates propagate to all queries
   - No stale pre-computed flags

2. **Storage Efficiency**
   - No redundant session flag columns (0/1 values)
   - Compression optimizes for actual data (price, volume)

3. **Flexibility**
   - Query different session definitions without reprocessing
   - Example: Regular hours vs extended hours on same dataset

4. **Maintainability**
   - Calendar logic isolated from data pipeline
   - Historical hour changes managed in calendar layer

---

### 5.2 Query-Time vs Storage-Time Detection

**Research Findings**: Industry overwhelmingly favors **query-time**

#### Query-Time Detection (Recommended)

**Pattern**:
```python
import exchange_calendars as xcals
import duckdb

# Load calendar
xnys = xcals.get_calendar("XNYS")

# Query with session filtering
conn = duckdb.connect("eurusd.duckdb")
result = conn.execute("""
    SELECT timestamp, bid, ask
    FROM ticks
    WHERE timestamp BETWEEN ? AND ?
""", [start, end]).fetchdf()

# Filter to trading minutes
trading_data = result[
    result['timestamp'].apply(lambda t: xnys.is_trading_minute(t))
]
```

**Advantages**:
- **Correctness**: Calendar updates retroactively fix historical queries
- **Storage**: No additional columns
- **Flexibility**: Multiple session definitions (regular, extended, custom)

**Disadvantage**:
- **Performance**: Repeated filtering if same query pattern

#### Storage-Time Detection (Rare, Specific Use Cases)

**Pattern**:
```python
# Pre-compute during ingestion
import exchange_calendars as xcals
xnys = xcals.get_calendar("XNYS")

df['is_trading_hour'] = df['timestamp'].apply(xnys.is_trading_minute)
df.to_parquet("ticks_with_flags.parquet")
```

**When to Use**:
- Single session definition (never changes)
- Query performance critical (same filter repeatedly)
- Storage cost negligible

**Disadvantages**:
- **Staleness**: Calendar updates require reprocessing entire dataset
- **Storage**: Additional column (mitigated by RLE compression)
- **Inflexibility**: Cannot query alternative session definitions

#### Hybrid Approach (Feature Stores)

**Pattern**: Pre-compute common flags, query-time for custom

**Source**: https://www.hopsworks.ai/dictionary/on-demand-features

```python
# Pre-compute standard session flags
df['nyse_regular_hours'] = ...
df['nyse_extended_hours'] = ...

# On-demand for custom sessions
df['custom_session'] = df['timestamp'].apply(custom_calendar.is_trading_minute)
```

**Benefits**:
- 80/20 rule: Pre-compute common cases, on-demand for edge cases
- Prevents online-offline skew (single source of truth)
- Shared across multiple models

**Cost**:
- Increased complexity
- Latency overhead for on-demand features

**Recommendation**: Query-time for forex (24-hour market, many overlapping sessions)

---

### 5.3 Lazy vs Eager Evaluation

**Source**: https://www.progress.com/blogs/lazy-vs-eager-evaluation

#### Lazy Evaluation (DuckDB, Polars)

**Pattern**: Build query plan, execute when result needed

```python
import duckdb

conn = duckdb.connect()
# This does NOT execute yet (lazy)
query = conn.execute("""
    SELECT timestamp, bid
    FROM ticks
    WHERE timestamp::TIME BETWEEN '09:30' AND '16:00'
""")

# Execution happens here (fetch result)
result = query.fetchdf()
```

**Advantages**:
- Query optimizer can eliminate unnecessary session checks
- Columnar databases skip reading irrelevant data
- Memory efficient for large datasets (streaming)

**Disadvantages**:
- Potential for memory leaks (unevaluated expressions)
- Debugging harder (errors occur at fetch time, not query time)

#### Eager Evaluation (Pandas, InfluxDB)

**Pattern**: Execute immediately, return result

```python
import pandas as pd

df = pd.read_parquet("ticks.parquet")
# This executes immediately (eager)
filtered = df[df['timestamp'].dt.time.between('09:30', '16:00')]
```

**Advantages**:
- Errors immediately detected
- Predictable performance
- Easier debugging

**Disadvantages**:
- Memory intensive for large datasets
- May perform unnecessary computations

#### Recommendation for Trading Hours

**Use Lazy** when:
- Billion-row datasets (forex tick data)
- Complex filters (multiple session types)
- Columnar databases (DuckDB, ClickHouse)

**Use Eager** when:
- Small datasets (<10M rows)
- Simple session filters
- Need immediate error detection (production validation)

---

### 5.4 Incremental Updates with Session Detection

**Pattern**: Append-only data with query-time session filtering

#### Example: Forex Tick Data Pipeline

**This Project** (exness-data-preprocess):
```python
from exness_data_preprocess import ExnessDataProcessor
import exchange_calendars as xcals

processor = ExnessDataProcessor()

# Download and store WITHOUT session flags
processor.download_and_store("EURUSD", "2024-10-01", "2024-10-31")

# Query with session filtering
xnys = xcals.get_calendar("XNYS")
conn = duckdb.connect("eurusd.duckdb")

# Filter to NYSE trading hours
result = conn.execute("""
    SELECT * FROM ticks
    WHERE timestamp::DATE = '2024-10-15'
""").fetchdf()

result['is_nyse_hours'] = result['timestamp'].apply(xnys.is_trading_minute)
```

**Benefits**:
- Incremental updates don't require session recomputation
- Single storage format serves multiple session definitions
- Calendar updates automatically apply to old data

---

## 6. Recommended Implementation for Forex Trading Hours

### 6.1 Architecture Recommendation

**Pattern**: Calendar Abstraction + DuckDB + Query-Time Filtering

```
┌────────────────────────────────────────┐
│  exchange_calendars                    │
│  ├─ XNYS (NYSE)                        │
│  ├─ XLON (London Stock Exchange)       │
│  ├─ XTKS (Tokyo Stock Exchange)        │
│  ├─ XHKG (Hong Kong Exchange)          │
│  └─ Custom Forex Session Calendars     │
└──────────────┬─────────────────────────┘
               │
               │ Query at Runtime
               │
┌──────────────▼─────────────────────────┐
│  DuckDB Storage                        │
│  ├─ eurusd.duckdb (all tick data)     │
│  ├─ usdjpy.duckdb                      │
│  └─ gbpusd.duckdb                      │
└────────────────────────────────────────┘
```

---

### 6.2 Implementation Example

#### Step 1: Define Custom Forex Session Calendars

```python
# custom_calendars.py
from exchange_calendars import ExchangeCalendar
from datetime import time
from zoneinfo import ZoneInfo
import pandas as pd

class ForexLondonSession(ExchangeCalendar):
    """London forex session: 8:00 AM - 4:00 PM GMT/BST"""

    name = "FOREX_LONDON"
    tz = ZoneInfo("Europe/London")
    open_time = time(8, 0)
    close_time = time(16, 0)

    @property
    def regular_holidays(self):
        # UK bank holidays
        return []  # Forex trades on holidays, but lower liquidity

    @property
    def special_closes(self):
        return []  # No special closes for forex

class ForexNewYorkSession(ExchangeCalendar):
    """New York forex session: 8:00 AM - 5:00 PM EST/EDT"""

    name = "FOREX_NEWYORK"
    tz = ZoneInfo("America/New_York")
    open_time = time(8, 0)
    close_time = time(17, 0)

class ForexTokyoSession(ExchangeCalendar):
    """Tokyo forex session: 9:00 AM - 6:00 PM JST"""

    name = "FOREX_TOKYO"
    tz = ZoneInfo("Asia/Tokyo")
    open_time = time(9, 0)
    close_time = time(18, 0)

class ForexSydneySession(ExchangeCalendar):
    """Sydney forex session: 9:00 AM - 5:00 PM AEST/AEDT"""

    name = "FOREX_SYDNEY"
    tz = ZoneInfo("Australia/Sydney")
    open_time = time(9, 0)
    close_time = time(17, 0)
```

#### Step 2: Register Custom Calendars

```python
import exchange_calendars as xcals

# Register custom calendars
xcals.register_calendar("FOREX_LONDON", ForexLondonSession())
xcals.register_calendar("FOREX_NEWYORK", ForexNewYorkSession())
xcals.register_calendar("FOREX_TOKYO", ForexTokyoSession())
xcals.register_calendar("FOREX_SYDNEY", ForexSydneySession())
```

#### Step 3: Query-Time Session Detection

```python
import duckdb
import exchange_calendars as xcals
from datetime import datetime
from zoneinfo import ZoneInfo

# Load calendars
london = xcals.get_calendar("FOREX_LONDON")
newyork = xcals.get_calendar("FOREX_NEWYORK")

# Connect to DuckDB
conn = duckdb.connect("eurusd.duckdb")

# Query tick data for specific date
result = conn.execute("""
    SELECT timestamp, bid, ask, bid_volume, ask_volume
    FROM ticks
    WHERE timestamp::DATE = '2024-10-15'
    ORDER BY timestamp
""").fetchdf()

# Add session flags (query-time)
result['london_session'] = result['timestamp'].apply(
    lambda t: london.is_trading_minute(t.astimezone(ZoneInfo("UTC")))
)
result['newyork_session'] = result['timestamp'].apply(
    lambda t: newyork.is_trading_minute(t.astimezone(ZoneInfo("UTC")))
)
result['london_ny_overlap'] = result['london_session'] & result['newyork_session']

# Filter to overlap period (highest liquidity)
overlap_data = result[result['london_ny_overlap']]
```

---

### 6.3 Performance Optimization

#### Option 1: Cache Session Boundaries (Amortized Cost)

```python
from functools import lru_cache

@lru_cache(maxsize=365)
def get_session_boundaries(date, session_name):
    """Cache session open/close times per date"""
    cal = xcals.get_calendar(session_name)
    if not cal.is_session(date):
        return None, None
    open_time = cal.session_open(date)
    close_time = cal.session_close(date)
    return open_time, close_time

# Use vectorized filtering
def is_in_session(timestamps, session_name):
    """Vectorized session check"""
    dates = timestamps.dt.date.unique()
    boundaries = {d: get_session_boundaries(d, session_name) for d in dates}

    return timestamps.apply(
        lambda t: boundaries[t.date()][0] <= t < boundaries[t.date()][1]
        if boundaries[t.date()][0] is not None else False
    )

result['london_session'] = is_in_session(result['timestamp'], "FOREX_LONDON")
```

**Performance Gain**: 365-day cache → 1 calendar lookup per day (not per row)

---

#### Option 2: DuckDB User-Defined Functions (UDF)

```python
import duckdb
from exchange_calendars import get_calendar

# Create UDF for session detection
def is_london_session(timestamp):
    cal = get_calendar("FOREX_LONDON")
    return cal.is_trading_minute(timestamp)

conn = duckdb.connect()
conn.create_function("is_london_session", is_london_session)

# Query with UDF
result = conn.execute("""
    SELECT
        timestamp,
        bid,
        ask,
        is_london_session(timestamp) AS london_session
    FROM ticks
    WHERE timestamp::DATE = '2024-10-15'
""").fetchdf()
```

**Performance**: UDF executes in DuckDB's vectorized engine (faster than Python apply)

---

#### Option 3: Pre-compute Session Lookup Table

```python
# Generate lookup table (once per calendar update)
import pandas as pd
import exchange_calendars as xcals

def generate_session_lookup(start_date, end_date, session_name):
    """Generate minute-level session lookup table"""
    cal = xcals.get_calendar(session_name)
    sessions = cal.sessions_in_range(start_date, end_date)

    lookup = []
    for session in sessions:
        minutes = cal.session_minutes(session)
        lookup.extend([(m, True) for m in minutes])

    return pd.DataFrame(lookup, columns=['timestamp', f'{session_name}_session'])

# Generate for 10 years
lookup = generate_session_lookup("2020-01-01", "2030-12-31", "FOREX_LONDON")
lookup.to_parquet("london_session_lookup.parquet")

# Join at query time
conn = duckdb.connect()
result = conn.execute("""
    SELECT t.*, l.FOREX_LONDON_session
    FROM ticks t
    LEFT JOIN 'london_session_lookup.parquet' l ON t.timestamp = l.timestamp
    WHERE t.timestamp::DATE = '2024-10-15'
""").fetchdf()
```

**Performance**: DuckDB columnar join on timestamp (highly optimized)

**Storage**: 10 years × 4 sessions × 1 minute granularity × 250 trading days/year
= ~5M rows × 2 columns (timestamp, bool) ≈ 50 MB (negligible)

**Recommended**: Option 3 for production (best query performance, acceptable storage)

---

### 6.4 Handling Edge Cases

#### DST Transition Handling

```python
from zoneinfo import ZoneInfo
from datetime import datetime

# ALWAYS store UTC in database
def normalize_to_utc(local_timestamp, local_tz):
    """Convert local timestamp to UTC"""
    local = local_timestamp.replace(tzinfo=ZoneInfo(local_tz))
    return local.astimezone(ZoneInfo("UTC"))

# Example: London session open on DST transition day
dst_transition = datetime(2024, 3, 31, 8, 0)  # BST starts (GMT → BST)
utc_open = normalize_to_utc(dst_transition, "Europe/London")
# Result: 2024-03-31 07:00:00 UTC (1 hour earlier in UTC after DST)

# Store in DuckDB
conn.execute("""
    INSERT INTO ticks (timestamp, bid, ask)
    VALUES (?, ?, ?)
""", [utc_open, 1.0850, 1.0852])
```

#### Historical Hour Changes

```python
# Tokyo exchange extended hours (Nov 5, 2024)
class ForexTokyoSession(ExchangeCalendar):
    def __init__(self):
        self.close_times = [
            (None, time(18, 0)),                    # Before Nov 5, 2024
            (pd.Timestamp("2024-11-05"), time(18, 30))  # After
        ]

    def session_close(self, date):
        for transition_date, close_time in reversed(self.close_times):
            if transition_date is None or date >= transition_date:
                return self._make_time(date, close_time)
```

#### Forex Weekend Gap

```python
def is_forex_trading(timestamp):
    """Forex trades 24/5: Sunday 22:00 UTC - Friday 22:00 UTC"""
    utc_time = timestamp.astimezone(ZoneInfo("UTC"))
    weekday = utc_time.weekday()
    hour = utc_time.hour

    # Friday after 22:00 UTC
    if weekday == 4 and hour >= 22:
        return False

    # Saturday (all day)
    if weekday == 5:
        return False

    # Sunday before 22:00 UTC
    if weekday == 6 and hour < 22:
        return False

    return True

result['is_trading'] = result['timestamp'].apply(is_forex_trading)
```

---

### 6.5 Multi-Exchange Session Tracking

**Pattern**: Multiple session columns for overlapping markets

```python
# Track all major exchange sessions simultaneously
sessions = {
    'NYSE': xcals.get_calendar('XNYS'),
    'LSE': xcals.get_calendar('XLON'),
    'TSE': xcals.get_calendar('XTKS'),
    'HKEX': xcals.get_calendar('XHKG'),
    'ASX': xcals.get_calendar('XASX'),
}

# Add all session flags
for name, cal in sessions.items():
    result[f'{name}_session'] = result['timestamp'].apply(
        lambda t: cal.is_trading_minute(t.astimezone(ZoneInfo("UTC")))
    )

# Count concurrent open exchanges
result['num_open_exchanges'] = result[
    [f'{name}_session' for name in sessions.keys()]
].sum(axis=1)

# Identify high-liquidity periods (3+ exchanges open)
result['high_liquidity'] = result['num_open_exchanges'] >= 3
```

---

## 7. Lessons Learned from Similar Systems

### 7.1 Don't Reinvent the Wheel

**Evidence**:
- **exchange_calendars**: Maintains 50+ exchanges, handles DST, historical changes
- **TradingHours.com**: Dedicated service for 1,000+ venues
- **Professional platforms**: Outsource calendar management

**Recommendation**: Use `exchange_calendars` or `pandas_market_calendars` rather than custom implementation

---

### 7.2 Separate Calendar Logic from Data Storage

**Anti-pattern**: Store session flags in tick data
```python
# DON'T DO THIS
df['is_nyse_hours'] = df['timestamp'].apply(is_nyse_trading)
df.to_parquet("ticks.parquet")  # Flags become stale
```

**Best Practice**: Query-time filtering
```python
# DO THIS
cal = xcals.get_calendar("XNYS")
filtered = df[df['timestamp'].apply(cal.is_trading_minute)]
```

---

### 7.3 UTC is Your Friend

**Lesson from Professional Systems**:
- **backtrader**: "Internally maintains data feed times in UTC"
- **zipline**: "Session label is midnight UTC"
- **QuantConnect**: UTC timestamps with timezone conversion for display

**Implementation**:
```python
# Store UTC in database
CREATE TABLE ticks (
    timestamp TIMESTAMPTZ PRIMARY KEY,  -- UTC timezone-aware
    bid DOUBLE,
    ask DOUBLE
);

# Convert to local for analysis
SELECT
    timestamp AT TIME ZONE 'America/New_York' AS local_time,
    bid, ask
FROM ticks;
```

---

### 7.4 Columnar Databases Shine for Session Filtering

**Performance Data**:
- **DuckDB**: 200x faster than row-based databases for filtered aggregations
- **ClickHouse**: Billions of rows with second-level queries
- **Arctic**: 25x speedup for quant model fitting

**Recommendation**: Use DuckDB for forex tick data (this project already does)

---

### 7.5 Test DST Transitions Explicitly

**Critical Dates for Testing**:
```python
# US DST transitions 2024
us_spring_forward = "2024-03-10 02:30"  # Non-existent time
us_fall_back = "2024-11-03 01:30"       # Ambiguous time

# UK DST transitions 2024
uk_spring_forward = "2024-03-31 01:30"
uk_fall_back = "2024-10-27 01:30"

# Test session detection on these dates
test_dates = [us_spring_forward, us_fall_back, uk_spring_forward, uk_fall_back]
for date in test_dates:
    assert_session_detection_works(date)
```

---

### 7.6 Version Your Calendars

**Pattern**: Track when calendar rules changed

```python
class VersionedCalendar:
    def __init__(self):
        self.versions = [
            {
                'start': None,
                'end': pd.Timestamp("2024-11-04"),
                'close_time': time(15, 0)
            },
            {
                'start': pd.Timestamp("2024-11-05"),
                'end': None,
                'close_time': time(15, 30)
            }
        ]

    def get_close_time(self, date):
        for version in self.versions:
            if (version['start'] is None or date >= version['start']) and \
               (version['end'] is None or date <= version['end']):
                return version['close_time']
```

**Benefit**: Accurate historical backtesting across calendar changes

---

## 8. Summary and Recommendations

### 8.1 Industry Standard Approach

**Pattern**: Calendar Abstraction + Columnar Storage + Query-Time Filtering

1. **Use exchange_calendars or pandas_market_calendars**
   - 50+ exchanges maintained by community
   - DST handling built-in
   - Historical hour changes supported

2. **Store tick data WITHOUT session flags**
   - Use DuckDB (already in this project)
   - UTC timestamps only
   - No pre-computed session columns

3. **Filter at query time**
   - Leverage DuckDB's columnar engine
   - Cache session boundaries (365 dates, not millions of rows)
   - Option: Pre-compute session lookup table (50 MB for 10 years)

---

### 8.2 Scalability Strategy

**For Billion-Row Datasets**:

1. **DuckDB columnar storage** ✅ (already using)
   - Sub-15ms queries
   - Automatic parallelization
   - Zone maps skip irrelevant data

2. **Session lookup table** (recommended addition)
   - 10 years × 4 sessions = 50 MB
   - DuckDB join on timestamp (highly optimized)
   - Update yearly or on calendar changes

3. **Avoid materialized views**
   - Unless <10 flag types
   - Write performance cost (2x+ overhead)
   - Storage-time pre-computation rarely justified

---

### 8.3 Edge Case Handling

**Must-Have**:
- ✅ UTC storage (already doing)
- ✅ `zoneinfo` for timezone conversion (Python 3.9+)
- ✅ Test DST transition dates explicitly
- ⚠️ Add calendar versioning support (Tokyo Nov 2024 change)

**Nice-to-Have**:
- Session overlap detection (London + New York)
- Weekend gap handling (Forex-specific)
- Holiday calendar integration (lower liquidity flags)

---

### 8.4 Implementation Checklist

#### Phase 1: Calendar Integration (Week 1)
- [ ] Install `exchange_calendars`: `pip install exchange_calendars`
- [ ] Define custom forex session calendars (London, NY, Tokyo, Sydney)
- [ ] Register calendars: `xcals.register_calendar()`
- [ ] Test session detection on sample dates

#### Phase 2: Session Lookup Table (Week 2)
- [ ] Generate 10-year session lookup (2020-2030)
- [ ] Store as Parquet: `london_session_lookup.parquet` (per session)
- [ ] Test DuckDB join performance: `LEFT JOIN ON timestamp`
- [ ] Benchmark vs query-time filtering

#### Phase 3: Query API Enhancement (Week 3)
- [ ] Add session filtering to query API
  ```python
  processor.query(
      symbol="EURUSD",
      start="2024-10-01",
      end="2024-10-31",
      sessions=["FOREX_LONDON", "FOREX_NEWYORK"]
  )
  ```
- [ ] Support session overlap queries
- [ ] Add session metadata to output DataFrame

#### Phase 4: Testing & Documentation (Week 4)
- [ ] Test DST transitions (Mar 10, Nov 3 for US; Mar 31, Oct 27 for UK)
- [ ] Test historical hour changes (Tokyo Nov 5, 2024)
- [ ] Test forex weekend gap (Friday 22:00 - Sunday 22:00 UTC)
- [ ] Document session detection patterns in `/Users/terryli/eon/exness-data-preprocess/docs/SESSION_DETECTION.md`

---

### 8.5 Code Example for This Project

**File**: `/Users/terryli/eon/exness-data-preprocess/src/exness_data_preprocess/session_detector.py`

```python
"""
Session detection for forex trading hours using exchange_calendars.
"""

import exchange_calendars as xcals
from exchange_calendars import ExchangeCalendar
from datetime import time
from zoneinfo import ZoneInfo
import pandas as pd
from functools import lru_cache

class ForexSessionDetector:
    """Detect trading sessions for forex instruments."""

    # Standard forex sessions
    SESSIONS = {
        'LONDON': ('Europe/London', time(8, 0), time(16, 0)),
        'NEWYORK': ('America/New_York', time(8, 0), time(17, 0)),
        'TOKYO': ('Asia/Tokyo', time(9, 0), time(18, 0)),
        'SYDNEY': ('Australia/Sydney', time(9, 0), time(17, 0)),
    }

    def __init__(self):
        """Initialize session detector with custom forex calendars."""
        self._register_forex_calendars()

    def _register_forex_calendars(self):
        """Register custom forex session calendars."""
        for name, (tz, open_time, close_time) in self.SESSIONS.items():
            cal = self._create_forex_calendar(name, tz, open_time, close_time)
            try:
                xcals.register_calendar(f"FOREX_{name}", cal)
            except xcals.errors.CalendarAlreadyRegistered:
                pass  # Already registered

    def _create_forex_calendar(self, name, tz_name, open_time, close_time):
        """Create custom forex session calendar."""
        class ForexSessionCalendar(ExchangeCalendar):
            name_attr = f"FOREX_{name}"
            tz = ZoneInfo(tz_name)
            open_time_default = open_time
            close_time_default = close_time

            @property
            def regular_holidays(self):
                return []  # Forex trades on holidays

        return ForexSessionCalendar()

    @lru_cache(maxsize=365 * 4)  # Cache 1 year × 4 sessions
    def get_session_boundaries(self, date, session_name):
        """Get session open/close times for a specific date (cached)."""
        cal = xcals.get_calendar(f"FOREX_{session_name}")
        if not cal.is_session(date):
            return None, None
        return cal.session_open(date), cal.session_close(date)

    def is_in_session(self, timestamp, session_name):
        """Check if timestamp is within specified session."""
        date = timestamp.date()
        open_time, close_time = self.get_session_boundaries(date, session_name)
        if open_time is None:
            return False
        return open_time <= timestamp < close_time

    def detect_sessions(self, df, sessions=None):
        """
        Add session flags to DataFrame.

        Args:
            df: DataFrame with 'timestamp' column (UTC)
            sessions: List of session names (default: all sessions)

        Returns:
            DataFrame with added session columns
        """
        if sessions is None:
            sessions = list(self.SESSIONS.keys())

        result = df.copy()
        for session in sessions:
            result[f'{session.lower()}_session'] = result['timestamp'].apply(
                lambda t: self.is_in_session(t, session)
            )

        return result

    def detect_overlaps(self, df):
        """Detect session overlaps (high liquidity periods)."""
        df = self.detect_sessions(df)

        # London + New York overlap (highest liquidity)
        df['london_ny_overlap'] = df['london_session'] & df['newyork_session']

        # Count concurrent open sessions
        session_cols = [f'{s.lower()}_session' for s in self.SESSIONS.keys()]
        df['num_open_sessions'] = df[session_cols].sum(axis=1)

        return df
```

**Usage**:
```python
from exness_data_preprocess import ExnessDataProcessor
from exness_data_preprocess.session_detector import ForexSessionDetector

# Load data
processor = ExnessDataProcessor()
df = processor.query("EURUSD", "2024-10-01", "2024-10-31")

# Detect sessions
detector = ForexSessionDetector()
df_with_sessions = detector.detect_sessions(df, sessions=['LONDON', 'NEWYORK'])

# Filter to London session only
london_data = df_with_sessions[df_with_sessions['london_session']]

# Detect overlaps
df_overlaps = detector.detect_overlaps(df)
high_liquidity = df_overlaps[df_overlaps['london_ny_overlap']]
```

---

## 9. References

### Libraries
- **exchange_calendars**: https://github.com/gerrymanoim/exchange_calendars
- **pandas_market_calendars**: https://github.com/rsheftel/pandas_market_calendars
- **zipline**: https://github.com/quantopian/zipline
- **backtrader**: https://www.backtrader.com
- **QuantConnect**: https://www.quantconnect.com/docs/v2/writing-algorithms/securities/market-hours

### Data Platforms
- **TradingHours.com**: https://www.tradinghours.com
- **Bloomberg**: https://www.bloomberg.com/professional/products/data/
- **QuantConnect**: https://www.quantconnect.com

### Databases
- **DuckDB**: https://duckdb.org
- **ClickHouse**: https://clickhouse.com
- **Arctic**: https://github.com/man-group/arctic
- **InfluxDB**: https://www.influxdata.com
- **QuestDB**: https://questdb.com

### Articles
- "My First Billion (of Rows) in DuckDB": https://towardsdatascience.com/my-first-billion-of-rows-in-duckdb-11873e5edbb5
- "DST Trading Hours Changes": https://fxglobe.com/daylight-saving-times-dts-2024-changes-to-trading-hours/
- "Tokyo Exchange Extends Hours": https://asia.nikkei.com/business/markets/tokyo-stock-exchange-moves-to-extend-trading-by-half-hour-in-2024

---

## 10. Appendix: Forex Session Hours Reference

### 10.1 Standard Forex Sessions (UTC)

| Session | Local Timezone | Local Hours | UTC Hours (Winter) | UTC Hours (Summer) |
|---------|----------------|-------------|-------------------|-------------------|
| **Sydney** | Australia/Sydney (AEDT/AEST) | 9:00 - 17:00 | 22:00 - 06:00 | 23:00 - 07:00 |
| **Tokyo** | Asia/Tokyo (JST) | 9:00 - 18:00 | 00:00 - 09:00 | 00:00 - 09:00 |
| **London** | Europe/London (GMT/BST) | 8:00 - 16:00 | 08:00 - 16:00 | 07:00 - 15:00 |
| **New York** | America/New_York (EST/EDT) | 8:00 - 17:00 | 13:00 - 22:00 | 12:00 - 21:00 |

**Note**: UTC hours vary due to DST transitions occurring on different dates across regions.

### 10.2 Session Overlaps (Highest Liquidity)

| Overlap | UTC Hours | Characteristics |
|---------|-----------|-----------------|
| **Sydney + Tokyo** | 00:00 - 06:00 UTC | Asian trading hours |
| **Tokyo + London** | 08:00 - 09:00 UTC | Brief overlap (1 hour) |
| **London + New York** | 13:00 - 16:00 UTC (winter)<br>12:00 - 15:00 UTC (summer) | **Highest liquidity** (50%+ of daily volume) |

### 10.3 DST Transition Dates 2024-2025

| Region | Spring Forward | Fall Back |
|--------|---------------|-----------|
| **US** | March 10, 2024 02:00 EST → EDT | November 3, 2024 02:00 EDT → EST |
| **UK** | March 31, 2024 01:00 GMT → BST | October 27, 2024 01:00 BST → GMT |
| **EU** | March 31, 2024 01:00 CET → CEST | October 27, 2024 01:00 CEST → CET |
| **Australia** | October 6, 2024 02:00 AEST → AEDT | April 6, 2025 03:00 AEDT → AEST |

**Critical Period**: March 10 - March 31 and October 27 - November 3 (US/UK misalignment)

---

**End of Research Document**

**Version**: 1.0
**Author**: Research synthesis from industry sources
**Last Updated**: 2025-10-17
